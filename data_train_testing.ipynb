{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "from load_data import *\n",
    "from model import *\n",
    "from plotting import *\n",
    "import tensorflow as tf \n",
    "import os\n",
    "from numpy import sqrt as sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos los ground truth del conjunto de entrenamiento y test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_train = open('JSON FILES\\DTS_SG_part_A.json')\n",
    "json_test = open('JSON FILES\\DTS_SG_part_A_TEST.json')\n",
    "paths_train = json.load(json_train)\n",
    "paths_test = json.load(json_test)\n",
    "\n",
    "#Cargamos la data \n",
    "train_GT = mLoad_GT(paths_train)\n",
    "train_img = mLoad_Img(paths_train)\n",
    "\n",
    "test_GT = mLoad_GT(paths_test)\n",
    "test_img = mLoad_Img(paths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(r'C:\\Users\\Usuario\\Documents\\Nueva carpeta\\Gaussian-Derivates-Network\\training\\resume.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.asarray(f['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos la red neuronal. Este sera un prototipo hasta siguiente cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos los sigmas\n",
    "input_sigma = []\n",
    "for i in range(6):\n",
    "    input_sigma.append(0.2015*(sqrt(2))**(i))\n",
    "    \n",
    "#Definimos el tama√±o de nuestra imagen.   \n",
    "input_shape = train_img[0,:,:,:].shape\n",
    "\n",
    "#Creamos el modelo\n",
    "model = Betsy(input_shape= input_shape, input_sigmas= input_sigma, input_kernel_size=(7, 7))\n",
    "\n",
    "\n",
    "#model.build_graph(input_shape).summary()\n",
    "#Compliamos el modelo\n",
    "model.compile(loss = GAME_loss,\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-6), \n",
    "              metrics = [sMAE(), RMSE()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un poco para testeo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training/cp-0044.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "#cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                 save_weights_only=True,\n",
    "#                                                 verbose=1)\n",
    "\n",
    "model.fit(train_img, \n",
    "          train_GT, \n",
    "          batch_size = batch_size, \n",
    "          epochs = 1, \n",
    "          validation_data=(test_img, test_GT)) \n",
    "          #callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained = r\"training\\cp-0050.ckpt\"\n",
    "model.load_weights(pre_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG = test_img[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334887.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32(tf.math.reduce_sum(IMG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DType' object has no attribute 'kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Usuario\\Documents\\Nueva carpeta\\Gaussian-Derivates-Network\\data_train_testing.ipynb Celda 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Usuario/Documents/Nueva%20carpeta/Gaussian-Derivates-Network/data_train_testing.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m count_estimate(test_img, test_GT, predict, model)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Nueva carpeta\\Gaussian-Derivates-Network\\plotting.py:19\u001b[0m, in \u001b[0;36mcount_estimate\u001b[1;34m(test_img, test_gt, predict, model)\u001b[0m\n\u001b[0;32m     16\u001b[0m est_count \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_sum(PRED)\n\u001b[0;32m     17\u001b[0m GT_count \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_sum(GT)\n\u001b[1;32m---> 19\u001b[0m resume\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mGT\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m GT_count\n\u001b[0;32m     20\u001b[0m resume\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mPred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m est_count\n\u001b[0;32m     21\u001b[0m \u001b[39m#resume.loc[i, 'Loss'] = est_loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[39m#est_MAE = model.get_loss(test_img, test_gt)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1580\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(value\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m value\n\u001b[0;32m   1579\u001b[0m     blk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mblocks[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1580\u001b[0m     take_split_path \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m blk\u001b[39m.\u001b[39;49m_can_hold_element(val)\n\u001b[0;32m   1582\u001b[0m \u001b[39m# if we have any multi-indexes that have non-trivial slices\u001b[39;00m\n\u001b[0;32m   1583\u001b[0m \u001b[39m# (not null slices) then we must take the split path, xref\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m \u001b[39m# GH 10360, GH 27841\u001b[39;00m\n\u001b[0;32m   1585\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(indexer, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(indexer) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39maxes):\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:610\u001b[0m, in \u001b[0;36mBlock._can_hold_element\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[39m\"\"\"require the same dtype as ourselves\"\"\"\u001b[39;00m\n\u001b[0;32m    609\u001b[0m element \u001b[39m=\u001b[39m extract_array(element, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 610\u001b[0m \u001b[39mreturn\u001b[39;00m can_hold_element(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, element)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:2181\u001b[0m, in \u001b[0;36mcan_hold_element\u001b[1;34m(arr, element)\u001b[0m\n\u001b[0;32m   2178\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2180\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2181\u001b[0m     np_can_hold_element(dtype, element)\n\u001b[0;32m   2182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:2264\u001b[0m, in \u001b[0;36mnp_can_hold_element\u001b[1;34m(dtype, element)\u001b[0m\n\u001b[0;32m   2261\u001b[0m \u001b[39melif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   2262\u001b[0m     \u001b[39mif\u001b[39;00m tipo \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2263\u001b[0m         \u001b[39m# TODO: itemsize check?\u001b[39;00m\n\u001b[1;32m-> 2264\u001b[0m         \u001b[39mif\u001b[39;00m tipo\u001b[39m.\u001b[39;49mkind \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   2265\u001b[0m             \u001b[39m# Anything other than float/integer we cannot hold\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n\u001b[0;32m   2267\u001b[0m         \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tipo, np\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m   2268\u001b[0m             \u001b[39m# i.e. nullable IntegerDtype or FloatingDtype;\u001b[39;00m\n\u001b[0;32m   2269\u001b[0m             \u001b[39m#  we can put this into an ndarray losslessly iff it has no NAs\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DType' object has no attribute 'kind'"
     ]
    }
   ],
   "source": [
    "count_estimate(test_img, test_GT, predict, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(predict[0,:,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e06ff7da33dc9620448857a90ad8b5f428f0d573d205a934d2841c8aee45ea32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
